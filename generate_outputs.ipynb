{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import torch as t\n",
    "import pandas as pd\n",
    "from tools.globals import load_country_globals\n",
    "\n",
    "from tools.nnsight_utils import  get_text_generations\n",
    "from tools.evaluation import get_answer_type_final\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tools.apis import OpenAIWrapper\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "load_country_globals()\n",
    "\n",
    "device = t.device(\n",
    "    \"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "load_dotenv()\n",
    "t.set_grad_enabled(False)\n",
    "\n",
    "t.manual_seed(42)\n",
    "if t.cuda.is_available():\n",
    "    t.cuda.manual_seed_all(42)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_suffix = {\n",
    "    \"English\": \"My guess is **\",\n",
    "    \"Turkish\": \"Tahminim **\",\n",
    "    \"French\": \"Ma supposition est **\",\n",
    "    \"Russian\": \"Моё предположение **\",\n",
    "    \"Bengali\": \"আমার অনুমান হলো **\",\n",
    "}\n",
    "\n",
    "subtask_map = {\n",
    "    \"synth_names\":\"names\",\n",
    "    \"synth_cities\":\"cities\",\n",
    "    \"culturebench\":\"culturebench\",\n",
    "}\n",
    "\n",
    "def eval_or_skip(txt):\n",
    "    try:\n",
    "        return eval(txt)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "country_to_suffix= {\"Turkey\": \"tr\", \"France\": \"fr\", \"Russia\": \"ru\", \"Bangladesh\": \"bn\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for the binary classification task\n",
    "final_df = pd.read_csv(\"data/binary/mcl_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for prefix analysis\n",
    "final_df = pd.read_csv(\"data/binary/mcl_dataset_prefix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23948, 15)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "options",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "hint",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ans_local_idx",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ans_west_idx",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ans_local",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ans_west",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subtask",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "translated",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "suffix",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cd8a7f97-c0b6-4123-9f2d-bb3ecf52012f",
       "rows": [
        [
         "0",
         "synth_names",
         "synth_names_0_tr",
         "Turkey",
         "Baklava Which of the following names is most likely to be my name?",
         "English",
         "['Liam', 'Alparslan']",
         "False",
         "2.0",
         "1.0",
         "Alparslan",
         "Liam",
         "Question:To answer the following multiple-choice question, you should choose one option only among 1,2,3,4. Instruction: You must select one option among 1,2,3,4. Do not output any other things.\nWhich of the following names is most likely to be my name?\nOptions:\n1. Liam\n2. Alparslan",
         "names",
         null,
         "Baklava"
        ],
        [
         "1",
         "synth_names",
         "synth_names_0_tr",
         "Turkey",
         "Istanbul Which of the following names is most likely to be my name?",
         "English",
         "['Liam', 'Alparslan']",
         "False",
         "2.0",
         "1.0",
         "Alparslan",
         "Liam",
         "Question:To answer the following multiple-choice question, you should choose one option only among 1,2,3,4. Instruction: You must select one option among 1,2,3,4. Do not output any other things.\nWhich of the following names is most likely to be my name?\nOptions:\n1. Liam\n2. Alparslan",
         "names",
         null,
         "Istanbul"
        ],
        [
         "2",
         "synth_names",
         "synth_names_0_tr",
         "Turkey",
         "Lira Which of the following names is most likely to be my name?",
         "English",
         "['Liam', 'Alparslan']",
         "False",
         "2.0",
         "1.0",
         "Alparslan",
         "Liam",
         "Question:To answer the following multiple-choice question, you should choose one option only among 1,2,3,4. Instruction: You must select one option among 1,2,3,4. Do not output any other things.\nWhich of the following names is most likely to be my name?\nOptions:\n1. Liam\n2. Alparslan",
         "names",
         null,
         "Lira"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>country</th>\n",
       "      <th>question</th>\n",
       "      <th>lang</th>\n",
       "      <th>options</th>\n",
       "      <th>hint</th>\n",
       "      <th>ans_local_idx</th>\n",
       "      <th>ans_west_idx</th>\n",
       "      <th>ans_local</th>\n",
       "      <th>ans_west</th>\n",
       "      <th>prompt</th>\n",
       "      <th>subtask</th>\n",
       "      <th>translated</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synth_names</td>\n",
       "      <td>synth_names_0_tr</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Baklava Which of the following names is most l...</td>\n",
       "      <td>English</td>\n",
       "      <td>[Liam, Alparslan]</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alparslan</td>\n",
       "      <td>Liam</td>\n",
       "      <td>Question:To answer the following multiple-choi...</td>\n",
       "      <td>names</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baklava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synth_names</td>\n",
       "      <td>synth_names_0_tr</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Istanbul Which of the following names is most ...</td>\n",
       "      <td>English</td>\n",
       "      <td>[Liam, Alparslan]</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alparslan</td>\n",
       "      <td>Liam</td>\n",
       "      <td>Question:To answer the following multiple-choi...</td>\n",
       "      <td>names</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Istanbul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synth_names</td>\n",
       "      <td>synth_names_0_tr</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Lira Which of the following names is most like...</td>\n",
       "      <td>English</td>\n",
       "      <td>[Liam, Alparslan]</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alparslan</td>\n",
       "      <td>Liam</td>\n",
       "      <td>Question:To answer the following multiple-choi...</td>\n",
       "      <td>names</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source_id       question_id country  \\\n",
       "0  synth_names  synth_names_0_tr  Turkey   \n",
       "1  synth_names  synth_names_0_tr  Turkey   \n",
       "2  synth_names  synth_names_0_tr  Turkey   \n",
       "\n",
       "                                            question     lang  \\\n",
       "0  Baklava Which of the following names is most l...  English   \n",
       "1  Istanbul Which of the following names is most ...  English   \n",
       "2  Lira Which of the following names is most like...  English   \n",
       "\n",
       "             options   hint  ans_local_idx  ans_west_idx  ans_local ans_west  \\\n",
       "0  [Liam, Alparslan]  False            2.0           1.0  Alparslan     Liam   \n",
       "1  [Liam, Alparslan]  False            2.0           1.0  Alparslan     Liam   \n",
       "2  [Liam, Alparslan]  False            2.0           1.0  Alparslan     Liam   \n",
       "\n",
       "                                              prompt subtask translated  \\\n",
       "0  Question:To answer the following multiple-choi...   names        NaN   \n",
       "1  Question:To answer the following multiple-choi...   names        NaN   \n",
       "2  Question:To answer the following multiple-choi...   names        NaN   \n",
       "\n",
       "     suffix  \n",
       "0   Baklava  \n",
       "1  Istanbul  \n",
       "2      Lira  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"options\"] = final_df[\"options\"].apply(eval_or_skip)\n",
    "final_df.dropna(subset=[\"options\"], inplace=True)\n",
    "final_df[\"subtask\"] = final_df[\"source_id\"].apply(lambda x: subtask_map.get(x, \"culturedistil\"))\n",
    "\n",
    "original_df = final_df.copy()\n",
    "original_df[\"swapped\"] = False\n",
    "\n",
    "print(final_df.shape)\n",
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_options(row):\n",
    "    row[\"options\"] = [row[\"options\"][1], row[\"options\"][0]]\n",
    "    row[[\"ans_local_idx\", \"ans_west_idx\"]] = row[[\"ans_west_idx\", \"ans_local_idx\"]]\n",
    "    return row\n",
    "\n",
    "swapped_df = final_df.copy()\n",
    "swapped_df = swapped_df.apply(swap_options, axis=1)\n",
    "swapped_df[\"swapped\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47896, 16)\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.concat([original_df, swapped_df])\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### via transformers library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"google/gemma-2-9b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=t.bfloat16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47896, 17)\n"
     ]
    }
   ],
   "source": [
    "from tools.prepare_input import prepare_dataset_it\n",
    "\n",
    "data_df = prepare_dataset_it(final_df, tokenizer)\n",
    "\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"google/gemma-2-9b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=t.bfloat16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.prepare_input import prepare_dataset_base\n",
    "\n",
    "data_df = prepare_dataset_base(final_df, tokenizer)\n",
    "\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 612/612 [10:36<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "inputs = [data_df[\"input\"].tolist()[k:k+batch_size] for k in range(0, len(data_df), batch_size)]\n",
    "\n",
    "all_generations = []\n",
    "for batch in tqdm(inputs):\n",
    "    generations = get_text_generations(model, tokenizer, batch, device, max_new_tokens=20)\n",
    "    all_generations.extend(generations)\n",
    "\n",
    "data_df[\"model\"] = \"aya_expanse_8b\"\n",
    "data_df[\"output\"] = all_generations\n",
    "data_df = data_df.apply(lambda x: get_answer_type_final(x, check_for=\"index\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"aya_expanse_8b_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### via API services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.prepare_input import prepare_dataset_it\n",
    "\n",
    "data_df = prepare_dataset_it(final_df)\n",
    "\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together_api = OpenAIWrapper(api_key=os.getenv(\"TOGETHER_AI_API_KEY\"),\n",
    "                           base_url=\"https://api.together.xyz/v1\")\n",
    "\n",
    "openai_api = OpenAIWrapper(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11974/11974 [05:22<00:00, 37.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "inputs = data_df[\"messages\"].tolist()\n",
    "\n",
    "def generate_text_llama_3_1_70b(imp):\n",
    "    return together_api.text_gen(imp, model_name=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\")\n",
    "\n",
    "def generate_text_gemma_2_27b(imp):\n",
    "    return together_api.text_gen(imp, model_name=\"google/gemma-2-27b-it\")\n",
    "\n",
    "def generate_text_gpt4o(imp):\n",
    "    return openai_api.text_gen(imp, model_name=\"gpt-4o\")\n",
    "\n",
    "# Example with GPT-4o\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    all_generations = list(tqdm(executor.map(generate_text_gpt4o, inputs), total=len(inputs)))\n",
    "\n",
    "data_df[\"output\"] = all_generations\n",
    "data_df[\"model\"] = \"gpt4o\"\n",
    "data_df = data_df.apply(lambda x: get_answer_type_final(x, check_for=\"index\"), axis=1)\n",
    "data_df.to_csv(\"gpt4o_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
